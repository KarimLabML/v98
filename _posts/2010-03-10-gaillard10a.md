---
title: Uniform regret bounds over $\mathbbR^d$ for the sequential linear regression
  problem with the square loss
abstract: "We consider the setting of online linear regression for arbitrary deterministic
  sequences,\r with the square loss. We are interested in the aim set by Bartlett
  et al. (2015):\r obtain regret bounds that hold uniformly over all competitor vectors.\r
  When the feature sequence is known at the beginning of the game, they provided closed-form\r
  regret bounds of $2d B^2 \\ln T + \\mathcal{O}_T(1)$, where $T$ is the number of
  rounds and $B$ is a\r bound on the observations. Instead, we derive bounds with
  an optimal constant of $1$ in front of\r the $d B^2 \\ln T$ term. In the case of
  sequentially revealed features, we also derive an asymptotic\r regret bound of $d
  B^2 \\ln T$ for any individual sequence of features and bounded observations.\r
  All our algorithms are variants of the online non-linear ridge regression forecaster,
  either with a\r data-dependent regularization or with almost no regularization."
layout: inproceedings
series: Proceedings of Machine Learning Research
id: gaillard10a
month: 0
tex_title: Uniform regret bounds over $\mathbb{R}^d$ for the sequential linear regression
  problem with the square loss
firstpage: 404
lastpage: 432
page: 404-432
order: 404
cycles: false
bibtex_author: Gaillard, Pierre and Gerchinovitz, S{\'e}bastien and Huard, Malo and
  Stoltz, Gilles
author:
- given: Pierre
  family: Gaillard
- given: SÃ©bastien
  family: Gerchinovitz
- given: Malo
  family: Huard
- given: Gilles
  family: Stoltz
date: 2010-03-10
address: 
publisher: PMLR
container-title: Proceedings of the 30th International Conference on Algorithmic Learning
  Theory
volume: '98'
genre: inproceedings
issued:
  date-parts:
  - 2010
  - 3
  - 10
pdf: http://proceedings.mlr.press/v98/gaillard10a/gaillard10a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
