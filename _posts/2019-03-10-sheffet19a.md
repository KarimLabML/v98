---
title: Old Techniques in Differentially Private Linear Regression
abstract: We introduce three novel differentially private algorithms that approximate
  the $2^{\rm nd}$-moment matrix of the data. These algorithms, which in contrast
  to existing algorithms always output positive-definite matrices, correspond to existing
  techniques in linear regression literature. Thus these techniques have an immediate
  interpretation and all results known about these techniques are straight-forwardly
  applicable to the outputs of these algorithms. More specifically, we discuss the
  following three techniques. (i) For Ridge Regression, we propose setting the regularization
  coefficient so that by approximating the solution using Johnson-Lindenstrauss transform
  we preserve privacy. (ii) We show that adding a batch of $d+O(\epsilon^{-2})$ random
  samples to our data preserves differential privacy. (iii) We show that sampling
  the $2^{\rm nd}$-moment matrix from a Bayesian posterior inverse-Wishart distribution
  is differentially private. We also give utility bounds for our algorithms and compare
  them with the existing “Analyze Gauss” algorithm of Dwork et al.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: sheffet19a
month: 0
tex_title: Old Techniques in Differentially Private Linear Regression
firstpage: 789
lastpage: 827
page: 789-827
order: 789
cycles: false
bibtex_author: Sheffet, Or
author:
- given: Or
  family: Sheffet
date: 2019-03-10
address: 
publisher: PMLR
container-title: Proceedings of the 30th International Conference on Algorithmic Learning
  Theory
volume: '98'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 3
  - 10
pdf: http://proceedings.mlr.press/v98/sheffet19a/sheffet19a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
