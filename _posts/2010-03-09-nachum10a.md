---
title: Average-Case Information Complexity of Learning
abstract: "How many bits of information are revealed by a learning algorithm for a
  concept class of VC-dimension $d$? Previous works have shown that even for $d=1$\r
  the amount of information may be unbounded (tend to $\\infty$ with the universe
  size). Can it be that all concepts in the class require leaking a large amount of
  information? We show that typically concepts do not require leakage. There exists
  a proper learning algorithm that reveals $O(d)$ bits of information for most concepts
  in the class.\r This result is a special case of a more general phenomenon we explore.\r
  If there is a low information learner when the algorithm  \\emph{knows} the underlying
  distribution on inputs, then there is a learner that reveals little information
  \ on an average concept  \\emph{without knowing} the distribution on inputs."
layout: inproceedings
series: Proceedings of Machine Learning Research
id: nachum10a
month: 0
tex_title: Average-Case Information Complexity of Learning
firstpage: 633
lastpage: 646
page: 633-646
order: 633
cycles: false
bibtex_author: Nachum, Ido and Yehudayoff, Amir
author:
- given: Ido
  family: Nachum
- given: Amir
  family: Yehudayoff
date: 2010-03-09
address: 
publisher: PMLR
container-title: Proceedings of the 30th International Conference on Algorithmic Learning
  Theory
volume: '98'
genre: inproceedings
issued:
  date-parts:
  - 2010
  - 3
  - 9
pdf: http://proceedings.mlr.press/v98/nachum10a/nachum10a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
